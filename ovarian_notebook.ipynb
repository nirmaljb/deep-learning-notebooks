{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "13-8jhR88MhwGaDbFWN84H711c3WqWMok",
      "authorship_tag": "ABX9TyOU76CoWmqDBjQcgWHem6LH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nirmaljb/deep-learning-notebooks/blob/main/ovarian_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "K6se_bUnBIJJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "3f1510e9-a844-4d80-919c-274f9fe9439d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     AFP     AG  Age   ALB  ALP  ALT  ...   RBC   RDW  TBIL    TP     UA  TYPE\n",
              "0   3.58  19.36   47  45.4   56   11  ...  2.64  13.7   5.5  73.9  396.4     0\n",
              "1  34.24  23.98   61  39.9   95    9  ...  4.89  12.7   6.8  72.0  119.2     0\n",
              "2   1.50  18.40   39  45.4   77    9  ...  4.62  12.0  14.8  77.9  209.2     0\n",
              "3   2.75  16.60   45  39.2   26   16  ...  4.01  14.6  10.9  66.1  215.6     0\n",
              "4   2.36  19.97   45  35.0   47   21  ...  4.40  13.4   5.3  66.5  206.0     0\n",
              "\n",
              "[5 rows x 50 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1f8788eb-e0b8-4a67-893b-97affd9b8a60\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AFP</th>\n",
              "      <th>AG</th>\n",
              "      <th>Age</th>\n",
              "      <th>ALB</th>\n",
              "      <th>ALP</th>\n",
              "      <th>ALT</th>\n",
              "      <th>AST</th>\n",
              "      <th>BASO#</th>\n",
              "      <th>BASO%</th>\n",
              "      <th>BUN</th>\n",
              "      <th>Ca</th>\n",
              "      <th>CA125</th>\n",
              "      <th>CA19-9</th>\n",
              "      <th>CA72-4</th>\n",
              "      <th>CEA</th>\n",
              "      <th>CL</th>\n",
              "      <th>CO2CP</th>\n",
              "      <th>CREA</th>\n",
              "      <th>DBIL</th>\n",
              "      <th>EO#</th>\n",
              "      <th>EO%</th>\n",
              "      <th>GGT</th>\n",
              "      <th>GLO</th>\n",
              "      <th>GLU.</th>\n",
              "      <th>HCT</th>\n",
              "      <th>HE4</th>\n",
              "      <th>HGB</th>\n",
              "      <th>IBIL</th>\n",
              "      <th>K</th>\n",
              "      <th>LYM#</th>\n",
              "      <th>LYM%</th>\n",
              "      <th>MCH</th>\n",
              "      <th>MCV</th>\n",
              "      <th>Menopause</th>\n",
              "      <th>Mg</th>\n",
              "      <th>MONO#</th>\n",
              "      <th>MONO%</th>\n",
              "      <th>MPV</th>\n",
              "      <th>Na</th>\n",
              "      <th>NEU</th>\n",
              "      <th>PCT</th>\n",
              "      <th>PDW</th>\n",
              "      <th>PHOS</th>\n",
              "      <th>PLT</th>\n",
              "      <th>RBC</th>\n",
              "      <th>RDW</th>\n",
              "      <th>TBIL</th>\n",
              "      <th>TP</th>\n",
              "      <th>UA</th>\n",
              "      <th>TYPE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.58</td>\n",
              "      <td>19.36</td>\n",
              "      <td>47</td>\n",
              "      <td>45.4</td>\n",
              "      <td>56</td>\n",
              "      <td>11</td>\n",
              "      <td>24</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.30</td>\n",
              "      <td>5.35</td>\n",
              "      <td>2.48</td>\n",
              "      <td>15.36</td>\n",
              "      <td>36.48</td>\n",
              "      <td>6.42</td>\n",
              "      <td>1.40</td>\n",
              "      <td>107.4</td>\n",
              "      <td>19.9</td>\n",
              "      <td>103.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.04</td>\n",
              "      <td>1.00</td>\n",
              "      <td>16</td>\n",
              "      <td>28.5</td>\n",
              "      <td>4.67</td>\n",
              "      <td>0.273</td>\n",
              "      <td>183.94</td>\n",
              "      <td>89.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>5.36</td>\n",
              "      <td>0.65</td>\n",
              "      <td>16.8</td>\n",
              "      <td>33.7</td>\n",
              "      <td>103.4</td>\n",
              "      <td>0</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0.22</td>\n",
              "      <td>5.70</td>\n",
              "      <td>11.70</td>\n",
              "      <td>141.3</td>\n",
              "      <td>76.2</td>\n",
              "      <td>0.09</td>\n",
              "      <td>13.4</td>\n",
              "      <td>1.46</td>\n",
              "      <td>74</td>\n",
              "      <td>2.64</td>\n",
              "      <td>13.7</td>\n",
              "      <td>5.5</td>\n",
              "      <td>73.9</td>\n",
              "      <td>396.4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>34.24</td>\n",
              "      <td>23.98</td>\n",
              "      <td>61</td>\n",
              "      <td>39.9</td>\n",
              "      <td>95</td>\n",
              "      <td>9</td>\n",
              "      <td>13</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.30</td>\n",
              "      <td>3.21</td>\n",
              "      <td>2.62</td>\n",
              "      <td>2444.00</td>\n",
              "      <td>19.98</td>\n",
              "      <td>10.17</td>\n",
              "      <td>2.46</td>\n",
              "      <td>100.1</td>\n",
              "      <td>22.3</td>\n",
              "      <td>45.0</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.50</td>\n",
              "      <td>13</td>\n",
              "      <td>32.1</td>\n",
              "      <td>10.50</td>\n",
              "      <td>0.417</td>\n",
              "      <td>934.10</td>\n",
              "      <td>128.0</td>\n",
              "      <td>4.2</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.27</td>\n",
              "      <td>17.2</td>\n",
              "      <td>26.2</td>\n",
              "      <td>85.3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.41</td>\n",
              "      <td>5.50</td>\n",
              "      <td>10.00</td>\n",
              "      <td>142.0</td>\n",
              "      <td>76.5</td>\n",
              "      <td>0.30</td>\n",
              "      <td>11.2</td>\n",
              "      <td>1.09</td>\n",
              "      <td>304</td>\n",
              "      <td>4.89</td>\n",
              "      <td>12.7</td>\n",
              "      <td>6.8</td>\n",
              "      <td>72.0</td>\n",
              "      <td>119.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.50</td>\n",
              "      <td>18.40</td>\n",
              "      <td>39</td>\n",
              "      <td>45.4</td>\n",
              "      <td>77</td>\n",
              "      <td>9</td>\n",
              "      <td>18</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.60</td>\n",
              "      <td>3.80</td>\n",
              "      <td>2.57</td>\n",
              "      <td>56.08</td>\n",
              "      <td>12.18</td>\n",
              "      <td>10.17</td>\n",
              "      <td>0.77</td>\n",
              "      <td>102.6</td>\n",
              "      <td>22.2</td>\n",
              "      <td>48.0</td>\n",
              "      <td>4.7</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.60</td>\n",
              "      <td>10</td>\n",
              "      <td>32.5</td>\n",
              "      <td>4.64</td>\n",
              "      <td>0.391</td>\n",
              "      <td>47.56</td>\n",
              "      <td>131.0</td>\n",
              "      <td>10.1</td>\n",
              "      <td>4.30</td>\n",
              "      <td>1.10</td>\n",
              "      <td>23.7</td>\n",
              "      <td>28.4</td>\n",
              "      <td>84.6</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>5.40</td>\n",
              "      <td>11.40</td>\n",
              "      <td>138.9</td>\n",
              "      <td>69.7</td>\n",
              "      <td>0.13</td>\n",
              "      <td>15.2</td>\n",
              "      <td>0.97</td>\n",
              "      <td>112</td>\n",
              "      <td>4.62</td>\n",
              "      <td>12.0</td>\n",
              "      <td>14.8</td>\n",
              "      <td>77.9</td>\n",
              "      <td>209.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.75</td>\n",
              "      <td>16.60</td>\n",
              "      <td>45</td>\n",
              "      <td>39.2</td>\n",
              "      <td>26</td>\n",
              "      <td>16</td>\n",
              "      <td>17</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.74</td>\n",
              "      <td>5.27</td>\n",
              "      <td>2.35</td>\n",
              "      <td>2555.00</td>\n",
              "      <td>18.41</td>\n",
              "      <td>131.60</td>\n",
              "      <td>0.82</td>\n",
              "      <td>103.2</td>\n",
              "      <td>24.0</td>\n",
              "      <td>65.7</td>\n",
              "      <td>2.9</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.07</td>\n",
              "      <td>17</td>\n",
              "      <td>26.9</td>\n",
              "      <td>4.76</td>\n",
              "      <td>0.372</td>\n",
              "      <td>853.50</td>\n",
              "      <td>123.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>4.70</td>\n",
              "      <td>1.73</td>\n",
              "      <td>27.2</td>\n",
              "      <td>30.6</td>\n",
              "      <td>92.6</td>\n",
              "      <td>1</td>\n",
              "      <td>1.11</td>\n",
              "      <td>0.42</td>\n",
              "      <td>6.55</td>\n",
              "      <td>7.38</td>\n",
              "      <td>139.1</td>\n",
              "      <td>65.5</td>\n",
              "      <td>0.25</td>\n",
              "      <td>17.4</td>\n",
              "      <td>1.25</td>\n",
              "      <td>339</td>\n",
              "      <td>4.01</td>\n",
              "      <td>14.6</td>\n",
              "      <td>10.9</td>\n",
              "      <td>66.1</td>\n",
              "      <td>215.6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.36</td>\n",
              "      <td>19.97</td>\n",
              "      <td>45</td>\n",
              "      <td>35.0</td>\n",
              "      <td>47</td>\n",
              "      <td>21</td>\n",
              "      <td>27</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.10</td>\n",
              "      <td>4.89</td>\n",
              "      <td>2.48</td>\n",
              "      <td>1391.00</td>\n",
              "      <td>11.15</td>\n",
              "      <td>10.17</td>\n",
              "      <td>0.42</td>\n",
              "      <td>99.6</td>\n",
              "      <td>26.2</td>\n",
              "      <td>70.3</td>\n",
              "      <td>2.2</td>\n",
              "      <td>0.11</td>\n",
              "      <td>1.60</td>\n",
              "      <td>24</td>\n",
              "      <td>31.5</td>\n",
              "      <td>4.07</td>\n",
              "      <td>0.383</td>\n",
              "      <td>404.90</td>\n",
              "      <td>122.0</td>\n",
              "      <td>3.1</td>\n",
              "      <td>4.77</td>\n",
              "      <td>1.98</td>\n",
              "      <td>28.8</td>\n",
              "      <td>27.7</td>\n",
              "      <td>87.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.08</td>\n",
              "      <td>0.69</td>\n",
              "      <td>10.00</td>\n",
              "      <td>10.40</td>\n",
              "      <td>141.0</td>\n",
              "      <td>59.5</td>\n",
              "      <td>0.28</td>\n",
              "      <td>11.9</td>\n",
              "      <td>0.94</td>\n",
              "      <td>272</td>\n",
              "      <td>4.40</td>\n",
              "      <td>13.4</td>\n",
              "      <td>5.3</td>\n",
              "      <td>66.5</td>\n",
              "      <td>206.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1f8788eb-e0b8-4a67-893b-97affd9b8a60')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1f8788eb-e0b8-4a67-893b-97affd9b8a60 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1f8788eb-e0b8-4a67-893b-97affd9b8a60');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "cancer"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "cancer = pd.read_csv('/content/drive/MyDrive/ovariantotal.csv')\n",
        "cancer.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cancer.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwKm5UM_W9mD",
        "outputId": "422fd4ae-2e50-46e2-ce80-6b0294aa2e01"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(349, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = cancer.drop('TYPE', axis=1)\n",
        "y = cancer['TYPE']"
      ],
      "metadata": {
        "id": "fmhtP7zRYyL1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "6IqZiKZaZeXy",
        "outputId": "e4663739-6786-48fc-d58b-a77ad879bc4c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      0\n",
              "1      0\n",
              "2      0\n",
              "3      0\n",
              "4      0\n",
              "      ..\n",
              "344    1\n",
              "345    1\n",
              "346    1\n",
              "347    1\n",
              "348    1\n",
              "Name: TYPE, Length: 349, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TYPE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>344</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>345</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>346</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>347</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>348</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>349 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "min_max_scalar = preprocessing.MinMaxScaler()\n",
        "X_scale = min_max_scalar.fit_transform(X)\n",
        "print(X_scale)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPT_1E-7ZlrN",
        "outputId": "2254d072-3ebb-468d-ffa0-4b98d70d1442"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2.45578349e-03 4.85071876e-01 4.70588235e-01 ... 8.37988827e-02\n",
            "  7.60667904e-01 5.60447761e-01]\n",
            " [2.78074070e-02 6.55363067e-01 6.76470588e-01 ... 1.20111732e-01\n",
            "  7.25417440e-01 4.32835821e-02]\n",
            " [7.35908185e-04 4.49686694e-01 3.52941176e-01 ... 3.43575419e-01\n",
            "  8.34879406e-01 2.11194030e-01]\n",
            " ...\n",
            " [1.83563615e-03 4.80280133e-01 6.47058824e-01 ... 3.15642458e-01\n",
            "  6.58627087e-01 2.11753731e-01]\n",
            " [1.01704165e-03 7.74788058e-01 2.20588235e-01 ... 2.45810056e-01\n",
            "  7.99628942e-01 3.53917910e-01]\n",
            " [8.26863129e-04 2.50645042e-01 3.52941176e-01 ... 1.62011173e-01\n",
            "  6.62337662e-01 1.65858209e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scale, y, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "qxE9-zMKbbjf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(32, activation='relu', input_dim=49))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKSV_kEVfBrQ",
        "outputId": "fd5d52c6-ccb5-48d7-b4db-cec1b3a7f446"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, batch_size=32, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khYM2FS3j6qD",
        "outputId": "27a90f82-0917-4ae2-f9c6-a737261fabe3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - accuracy: 0.4935 - loss: 0.7018\n",
            "Epoch 2/5\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7535 - loss: 0.6586 \n",
            "Epoch 3/5\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7700 - loss: 0.6369 \n",
            "Epoch 4/5\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8018 - loss: 0.6052 \n",
            "Epoch 5/5\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7909 - loss: 0.5860 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x780731ea9040>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ug5kEY49nao1",
        "outputId": "cdd129c5-e010-455f-8c5d-b44ce8684586"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.59752107],\n",
              "       [0.4489999 ],\n",
              "       [0.5814329 ],\n",
              "       [0.3197496 ],\n",
              "       [0.62882906],\n",
              "       [0.6428241 ],\n",
              "       [0.65969306],\n",
              "       [0.4356927 ],\n",
              "       [0.3346298 ],\n",
              "       [0.641931  ],\n",
              "       [0.6200284 ],\n",
              "       [0.42994237],\n",
              "       [0.68614185],\n",
              "       [0.44336852],\n",
              "       [0.30267277],\n",
              "       [0.5628011 ],\n",
              "       [0.5618457 ],\n",
              "       [0.6406437 ],\n",
              "       [0.6646185 ],\n",
              "       [0.47346988],\n",
              "       [0.58394045],\n",
              "       [0.5972068 ],\n",
              "       [0.39260972],\n",
              "       [0.6329581 ],\n",
              "       [0.31900078],\n",
              "       [0.61946887],\n",
              "       [0.28309372],\n",
              "       [0.37149683],\n",
              "       [0.3222892 ],\n",
              "       [0.68222404],\n",
              "       [0.529887  ],\n",
              "       [0.48394266],\n",
              "       [0.33354074],\n",
              "       [0.36509576],\n",
              "       [0.40904525],\n",
              "       [0.23783025],\n",
              "       [0.54364073],\n",
              "       [0.6010547 ],\n",
              "       [0.38362077],\n",
              "       [0.43950802],\n",
              "       [0.6024899 ],\n",
              "       [0.59972125],\n",
              "       [0.620496  ],\n",
              "       [0.6427643 ],\n",
              "       [0.65126306],\n",
              "       [0.27779245],\n",
              "       [0.44133803],\n",
              "       [0.6089058 ],\n",
              "       [0.40101177],\n",
              "       [0.4568876 ],\n",
              "       [0.58554494],\n",
              "       [0.63980514],\n",
              "       [0.38310444],\n",
              "       [0.39751056],\n",
              "       [0.5266808 ],\n",
              "       [0.6180512 ],\n",
              "       [0.4831278 ],\n",
              "       [0.6635938 ],\n",
              "       [0.44674864],\n",
              "       [0.6307037 ],\n",
              "       [0.6629577 ],\n",
              "       [0.4220075 ],\n",
              "       [0.3716227 ],\n",
              "       [0.6915499 ],\n",
              "       [0.2785805 ],\n",
              "       [0.51449335],\n",
              "       [0.42461616],\n",
              "       [0.6398659 ],\n",
              "       [0.55749464],\n",
              "       [0.41684029]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.where(y_pred > 0.5, 1, 0)\n",
        "y_pred = y_pred.astype(int)\n",
        "import numpy as np\n",
        "\n",
        "np.column_stack((y_pred, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KkcqxHcBoBwI",
        "outputId": "8c6b90e6-ba39-4d22-92ac-8b617ef9ee55"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [0, 1],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [1, 0],\n",
              "       [0, 0],\n",
              "       [1, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [1, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [1, 0],\n",
              "       [1, 1],\n",
              "       [0, 1],\n",
              "       [0, 0],\n",
              "       [1, 0],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [1, 0],\n",
              "       [1, 1],\n",
              "       [0, 1],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [1, 0],\n",
              "       [0, 0],\n",
              "       [1, 0],\n",
              "       [1, 1],\n",
              "       [0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BPLwgbPo2UG",
        "outputId": "dcb84570-b881-46da-b014-136023037b0d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[30 11]\n",
            " [ 3 26]]\n",
            "0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dropout\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(32, activation='relu', input_dim=49))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "#output\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjEh9Jgjplnf",
        "outputId": "11e4f1ca-1eef-43df-c26a-9052b25ed8f6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, validation_split=0.2, batch_size=32, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orKRZXJkt4-E",
        "outputId": "e4c150a8-a40f-44dd-c0f0-9f6de8441890"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 376ms/step - accuracy: 0.5977 - loss: 0.6573 - val_accuracy: 0.7143 - val_loss: 0.6521\n",
            "Epoch 2/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6372 - loss: 0.6602 - val_accuracy: 0.6786 - val_loss: 0.6372\n",
            "Epoch 3/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5943 - loss: 0.6642 - val_accuracy: 0.6964 - val_loss: 0.6279\n",
            "Epoch 4/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7060 - loss: 0.6034 - val_accuracy: 0.7321 - val_loss: 0.6171\n",
            "Epoch 5/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6782 - loss: 0.6128 - val_accuracy: 0.7679 - val_loss: 0.6070\n",
            "Epoch 6/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7094 - loss: 0.6111 - val_accuracy: 0.7679 - val_loss: 0.5912\n",
            "Epoch 7/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7091 - loss: 0.5974 - val_accuracy: 0.7857 - val_loss: 0.5800\n",
            "Epoch 8/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6951 - loss: 0.5782 - val_accuracy: 0.7679 - val_loss: 0.5699\n",
            "Epoch 9/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7094 - loss: 0.5591 - val_accuracy: 0.7857 - val_loss: 0.5670\n",
            "Epoch 10/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7456 - loss: 0.5528 - val_accuracy: 0.7857 - val_loss: 0.5466\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78072432d280>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred\n",
        "y_pred = np.where(y_pred > 0.5, 1, 0)\n",
        "y_pred = y_pred.astype(int)\n",
        "import numpy as np\n",
        "\n",
        "np.column_stack((y_pred, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CV09VEuyutir",
        "outputId": "a0338ccb-42d4-465b-ce4f-76f92c927cea"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [0, 1],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [1, 0],\n",
              "       [0, 0],\n",
              "       [1, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [1, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [1, 0],\n",
              "       [1, 1],\n",
              "       [0, 1],\n",
              "       [0, 0],\n",
              "       [1, 0],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [1, 0],\n",
              "       [1, 1],\n",
              "       [0, 1],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [1, 0],\n",
              "       [1, 1],\n",
              "       [0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfEQnSmUvgsD",
        "outputId": "d0631761-f20f-4dfc-9749-57536e01ad77"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[31 10]\n",
            " [ 3 26]]\n",
            "0.8142857142857143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(32, activation='relu', input_dim=49))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "#output\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gfW--CMwhgg",
        "outputId": "d5468c9b-f79e-4551-d0b3-7fbb80a608b3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, validation_split=0.2, batch_size=8, epochs=100, callbacks=[early_stop], verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFLCHFzS6K6N",
        "outputId": "053c8455-b2bc-43a1-8abe-cc917d05e0c3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 71ms/step - accuracy: 0.5480 - loss: 0.6845 - val_accuracy: 0.7321 - val_loss: 0.6514\n",
            "Epoch 2/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6678 - loss: 0.6381 - val_accuracy: 0.7679 - val_loss: 0.6333\n",
            "Epoch 3/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6288 - loss: 0.6288 - val_accuracy: 0.7143 - val_loss: 0.5974\n",
            "Epoch 4/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7215 - loss: 0.5982 - val_accuracy: 0.7857 - val_loss: 0.5736\n",
            "Epoch 5/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7615 - loss: 0.5582 - val_accuracy: 0.7679 - val_loss: 0.5370\n",
            "Epoch 6/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7267 - loss: 0.5555 - val_accuracy: 0.8036 - val_loss: 0.5305\n",
            "Epoch 7/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7419 - loss: 0.5417 - val_accuracy: 0.7321 - val_loss: 0.5012\n",
            "Epoch 8/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7379 - loss: 0.5140 - val_accuracy: 0.8036 - val_loss: 0.4925\n",
            "Epoch 9/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8001 - loss: 0.4158 - val_accuracy: 0.8036 - val_loss: 0.4796\n",
            "Epoch 10/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8066 - loss: 0.4449 - val_accuracy: 0.8214 - val_loss: 0.4843\n",
            "Epoch 11/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7882 - loss: 0.4609 - val_accuracy: 0.7500 - val_loss: 0.4702\n",
            "Epoch 12/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7849 - loss: 0.4819 - val_accuracy: 0.8036 - val_loss: 0.5001\n",
            "Epoch 13/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8012 - loss: 0.4555 - val_accuracy: 0.7857 - val_loss: 0.4650\n",
            "Epoch 14/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8116 - loss: 0.4125 - val_accuracy: 0.8214 - val_loss: 0.4671\n",
            "Epoch 15/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8332 - loss: 0.3848 - val_accuracy: 0.7500 - val_loss: 0.4623\n",
            "Epoch 16/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8130 - loss: 0.4340 - val_accuracy: 0.8036 - val_loss: 0.4884\n",
            "Epoch 17/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8032 - loss: 0.4302 - val_accuracy: 0.8214 - val_loss: 0.4586\n",
            "Epoch 18/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8139 - loss: 0.3951 - val_accuracy: 0.7857 - val_loss: 0.4560\n",
            "Epoch 19/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8084 - loss: 0.4055 - val_accuracy: 0.7500 - val_loss: 0.5090\n",
            "Epoch 20/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8164 - loss: 0.4187 - val_accuracy: 0.8036 - val_loss: 0.4500\n",
            "Epoch 21/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8012 - loss: 0.4359 - val_accuracy: 0.8036 - val_loss: 0.4686\n",
            "Epoch 22/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8569 - loss: 0.3303 - val_accuracy: 0.8036 - val_loss: 0.4880\n",
            "Epoch 23/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8350 - loss: 0.3703 - val_accuracy: 0.8214 - val_loss: 0.4497\n",
            "Epoch 24/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8105 - loss: 0.4160 - val_accuracy: 0.8036 - val_loss: 0.4457\n",
            "Epoch 25/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8457 - loss: 0.3761 - val_accuracy: 0.7857 - val_loss: 0.4545\n",
            "Epoch 26/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8540 - loss: 0.3342 - val_accuracy: 0.7857 - val_loss: 0.4769\n",
            "Epoch 27/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8734 - loss: 0.3323 - val_accuracy: 0.7679 - val_loss: 0.4488\n",
            "Epoch 28/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8479 - loss: 0.3575 - val_accuracy: 0.7679 - val_loss: 0.4484\n",
            "Epoch 29/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8755 - loss: 0.3222 - val_accuracy: 0.7679 - val_loss: 0.4572\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x780713513f50>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred\n",
        "y_pred = np.where(y_pred > 0.5, 1, 0)\n",
        "y_pred = y_pred.astype(int)\n",
        "import numpy as np\n",
        "\n",
        "np.column_stack((y_pred, y_test))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdeMi8gp7MUw",
        "outputId": "9771a80d-4e69-429a-bc91-5e1df29ee9c6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7807101ea2a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 207ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7807101ea2a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
            "[[30 11]\n",
            " [ 3 26]]\n",
            "0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models, regularizers\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(32, activation='relu', kernel_regularizer=regularizers.L1(0.001), input_dim=49))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(32, activation='relu', kernel_regularizer=regularizers.L1(0.001)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "#output\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZPwvIzu7VRd",
        "outputId": "608fad73-8b02-42fd-9c0c-ea370bc0c371"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, validation_split=0.2, batch_size=8, epochs=100, callbacks=[early_stop], verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6QNMdyapMnda",
        "outputId": "4b046d18-168e-4b83-f710-48e2d588e25e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step - accuracy: 0.4687 - loss: 1.0681 - val_accuracy: 0.5893 - val_loss: 1.0187\n",
            "Epoch 2/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5700 - loss: 1.0075 - val_accuracy: 0.8036 - val_loss: 0.9739\n",
            "Epoch 3/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5929 - loss: 0.9851 - val_accuracy: 0.7500 - val_loss: 0.9267\n",
            "Epoch 4/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6662 - loss: 0.9281 - val_accuracy: 0.7679 - val_loss: 0.8870\n",
            "Epoch 5/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6951 - loss: 0.8779 - val_accuracy: 0.7321 - val_loss: 0.8581\n",
            "Epoch 6/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7312 - loss: 0.8486 - val_accuracy: 0.7500 - val_loss: 0.8129\n",
            "Epoch 7/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8125 - loss: 0.7833 - val_accuracy: 0.7500 - val_loss: 0.7850\n",
            "Epoch 8/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7024 - loss: 0.7944 - val_accuracy: 0.7679 - val_loss: 0.7434\n",
            "Epoch 9/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7279 - loss: 0.7627 - val_accuracy: 0.8036 - val_loss: 0.7238\n",
            "Epoch 10/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7983 - loss: 0.6886 - val_accuracy: 0.7679 - val_loss: 0.7214\n",
            "Epoch 11/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7657 - loss: 0.7118 - val_accuracy: 0.7500 - val_loss: 0.6826\n",
            "Epoch 12/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6982 - loss: 0.7237 - val_accuracy: 0.8036 - val_loss: 0.6710\n",
            "Epoch 13/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7819 - loss: 0.6710 - val_accuracy: 0.7679 - val_loss: 0.6802\n",
            "Epoch 14/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8112 - loss: 0.5991 - val_accuracy: 0.7500 - val_loss: 0.7124\n",
            "Epoch 15/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7512 - loss: 0.6494 - val_accuracy: 0.7679 - val_loss: 0.6560\n",
            "Epoch 16/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8175 - loss: 0.6248 - val_accuracy: 0.7857 - val_loss: 0.6583\n",
            "Epoch 17/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7822 - loss: 0.6192 - val_accuracy: 0.7500 - val_loss: 0.6996\n",
            "Epoch 18/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8108 - loss: 0.6036 - val_accuracy: 0.8214 - val_loss: 0.6285\n",
            "Epoch 19/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7403 - loss: 0.6660 - val_accuracy: 0.7679 - val_loss: 0.6344\n",
            "Epoch 20/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8592 - loss: 0.5632 - val_accuracy: 0.7500 - val_loss: 0.6297\n",
            "Epoch 21/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8572 - loss: 0.5230 - val_accuracy: 0.8214 - val_loss: 0.6201\n",
            "Epoch 22/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7569 - loss: 0.6170 - val_accuracy: 0.7679 - val_loss: 0.6179\n",
            "Epoch 23/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7863 - loss: 0.5797 - val_accuracy: 0.7857 - val_loss: 0.6244\n",
            "Epoch 24/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7585 - loss: 0.5729 - val_accuracy: 0.7857 - val_loss: 0.6124\n",
            "Epoch 25/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8611 - loss: 0.5184 - val_accuracy: 0.7500 - val_loss: 0.6346\n",
            "Epoch 26/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8127 - loss: 0.5639 - val_accuracy: 0.7500 - val_loss: 0.6289\n",
            "Epoch 27/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7992 - loss: 0.5556 - val_accuracy: 0.8036 - val_loss: 0.6041\n",
            "Epoch 28/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8416 - loss: 0.5406 - val_accuracy: 0.7857 - val_loss: 0.6153\n",
            "Epoch 29/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8500 - loss: 0.4969 - val_accuracy: 0.8393 - val_loss: 0.5939\n",
            "Epoch 30/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8865 - loss: 0.4601 - val_accuracy: 0.7857 - val_loss: 0.5996\n",
            "Epoch 31/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8479 - loss: 0.5271 - val_accuracy: 0.8036 - val_loss: 0.6002\n",
            "Epoch 32/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8177 - loss: 0.5666 - val_accuracy: 0.8214 - val_loss: 0.5975\n",
            "Epoch 33/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8142 - loss: 0.5637 - val_accuracy: 0.8036 - val_loss: 0.5931\n",
            "Epoch 34/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8001 - loss: 0.5419 - val_accuracy: 0.8393 - val_loss: 0.5874\n",
            "Epoch 35/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8148 - loss: 0.5324 - val_accuracy: 0.7857 - val_loss: 0.5948\n",
            "Epoch 36/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8792 - loss: 0.4518 - val_accuracy: 0.7857 - val_loss: 0.5989\n",
            "Epoch 37/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8625 - loss: 0.4569 - val_accuracy: 0.7857 - val_loss: 0.6003\n",
            "Epoch 38/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8397 - loss: 0.5029 - val_accuracy: 0.7857 - val_loss: 0.5854\n",
            "Epoch 39/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8742 - loss: 0.4807 - val_accuracy: 0.8036 - val_loss: 0.5814\n",
            "Epoch 40/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8730 - loss: 0.4905 - val_accuracy: 0.7679 - val_loss: 0.5845\n",
            "Epoch 41/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8276 - loss: 0.4908 - val_accuracy: 0.8036 - val_loss: 0.5759\n",
            "Epoch 42/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8468 - loss: 0.4666 - val_accuracy: 0.7500 - val_loss: 0.6131\n",
            "Epoch 43/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8662 - loss: 0.4620 - val_accuracy: 0.7857 - val_loss: 0.5761\n",
            "Epoch 44/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8831 - loss: 0.4776 - val_accuracy: 0.8214 - val_loss: 0.5709\n",
            "Epoch 45/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8755 - loss: 0.4567 - val_accuracy: 0.8036 - val_loss: 0.5711\n",
            "Epoch 46/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8434 - loss: 0.5260 - val_accuracy: 0.8214 - val_loss: 0.5620\n",
            "Epoch 47/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8632 - loss: 0.4612 - val_accuracy: 0.8214 - val_loss: 0.5622\n",
            "Epoch 48/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8815 - loss: 0.4485 - val_accuracy: 0.7500 - val_loss: 0.6232\n",
            "Epoch 49/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8748 - loss: 0.4675 - val_accuracy: 0.7857 - val_loss: 0.5631\n",
            "Epoch 50/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8429 - loss: 0.4762 - val_accuracy: 0.8036 - val_loss: 0.5671\n",
            "Epoch 51/100\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8892 - loss: 0.4554 - val_accuracy: 0.7679 - val_loss: 0.6581\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x780724307620>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred\n",
        "y_pred = np.where(y_pred > 0.5, 1, 0)\n",
        "y_pred = y_pred.astype(int)\n",
        "import numpy as np\n",
        "\n",
        "np.column_stack((y_pred, y_test))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7AyN-LpNtm0",
        "outputId": "00735184-ace3-46e1-98c1-cbefb78293e6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 173ms/step\n",
            "[[30 11]\n",
            " [ 1 28]]\n",
            "0.8285714285714286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VmRcQx1DNv_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "print(keras.__version__)\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "Z2dCafGV8zeH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}